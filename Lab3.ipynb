{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKuAWk5k46fUGO/dixBoI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajparikh18/Statistical-Inference-Collab-Work/blob/main/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d112e37f"
      },
      "source": [
        "### 1. Dataset Loading and Handling Imbalance\n",
        "\n",
        "The `load_credit_card_dataset` method attempts to load the data from a specified file path. If the file is not found, it automatically creates a synthetic dataset with a similar class imbalance to ensure the analysis can proceed. The `sample_dataset_for_analysis` method is included to optionally reduce the dataset size for faster computation while preserving the class distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ba0b8b6"
      },
      "source": [
        "# From the original code, within the CreditCardFraudAnalyzer class:\n",
        "# (Only showing the relevant methods)\n",
        "\n",
        "def load_credit_card_dataset(self, file_path):\n",
        "    \"\"\"\n",
        "    Load the Credit Card Fraud Detection dataset\n",
        "\n",
        "    Parameters:\n",
        "    - file_path: Path to the creditcard.csv file\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"Loading Credit Card Fraud Detection dataset...\")\n",
        "        self.df = pd.read_csv(file_path)\n",
        "        self.X = self.df.drop('Class', axis=1).values\n",
        "        self.y = self.df['Class'].values\n",
        "        self.class_distribution = Counter(self.y)\n",
        "        self.dataset_info = {\n",
        "            'total_samples': len(self.y),\n",
        "            'n_features': self.X.shape[1],\n",
        "            'normal_transactions': self.class_distribution[0],\n",
        "            'fraud_transactions': self.class_distribution[1],\n",
        "            'fraud_percentage': (self.class_distribution[1] / len(self.y)) * 100\n",
        "        }\n",
        "        print(\"Dataset loaded successfully!\")\n",
        "        print(f\"Total samples: {self.dataset_info['total_samples']:,}\")\n",
        "        print(f\"Features: {self.dataset_info['n_features']}\")\n",
        "        print(f\"Normal transactions: {self.dataset_info['normal_transactions']:,} ({(self.class_distribution[0]/len(self.y)*100):.2f}%)\")\n",
        "        print(f\"Fraud transactions: {self.dataset_info['fraud_transactions']:,} ({self.dataset_info['fraud_percentage']:.3f}%)\")\n",
        "        print(f\"Imbalance ratio: 1:{self.class_distribution[0]/self.class_distribution[1]:.0f}\")\n",
        "        return self.X, self.y\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{file_path}' not found!\")\n",
        "        print(\"\\nPlease download the dataset from:\")\n",
        "        print(\"https://www.kaggle.com/mlg-ulb/creditcardfraud\")\n",
        "        print(\"\\nOr ensure the file path is correct.\")\n",
        "        print(\"\\nCreating synthetic dataset with similar characteristics as a fallback...\")\n",
        "        return self.create_synthetic_fraud_dataset()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "        print(\"Creating synthetic dataset as fallback...\")\n",
        "        return self.create_synthetic_fraud_dataset()\n",
        "\n",
        "def create_synthetic_fraud_dataset(self):\n",
        "    \"\"\"\n",
        "    Create a synthetic dataset similar to credit card fraud data\n",
        "    \"\"\"\n",
        "    from sklearn.datasets import make_classification\n",
        "    X, y = make_classification(\n",
        "        n_samples=100000, # Reduced size for faster computation\n",
        "        n_features=30,\n",
        "        n_informative=25,\n",
        "        n_redundant=3,\n",
        "        n_clusters_per_class=1,\n",
        "        weights=[0.9983, 0.0017], # Similar to real fraud ratio\n",
        "        flip_y=0.001,\n",
        "        random_state=self.random_state\n",
        "    )\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.class_distribution = Counter(y)\n",
        "    feature_names = [f'V{i+1}' for i in range(29)] + ['Amount']\n",
        "    self.df = pd.DataFrame(X, columns=feature_names)\n",
        "    self.df['Class'] = y\n",
        "    self.dataset_info = {\n",
        "        'total_samples': len(y),\n",
        "        'n_features': X.shape[1],\n",
        "        'normal_transactions': self.class_distribution[0],\n",
        "        'fraud_transactions': self.class_distribution[1],\n",
        "        'fraud_percentage': (self.class_distribution[1] / len(y)) * 100\n",
        "    }\n",
        "    print(\"Synthetic fraud dataset created!\")\n",
        "    print(f\"Total samples: {self.dataset_info['total_samples']:,}\")\n",
        "    print(f\"Normal transactions: {self.dataset_info['normal_transactions']:,}\")\n",
        "    print(f\"Fraud transactions: {self.dataset_info['fraud_transactions']:,}\")\n",
        "    print(f\"Fraud percentage: {self.dataset_info['fraud_percentage']:.3f}%\")\n",
        "    return X, y\n",
        "\n",
        "def sample_dataset_for_analysis(self, sample_size=10000):\n",
        "    \"\"\"\n",
        "    Sample the dataset for faster analysis while maintaining class distribution\n",
        "\n",
        "    Parameters:\n",
        "    - sample_size: Number of samples to use for analysis\n",
        "    \"\"\"\n",
        "    if len(self.y) > sample_size:\n",
        "        print(f\"\\nSampling {sample_size:,} samples for analysis (maintaining class distribution)...\")\n",
        "        fraud_ratio = self.class_distribution[1] / len(self.y)\n",
        "        n_fraud_samples = max(int(sample_size * fraud_ratio), 50) # Ensure minimum fraud samples\n",
        "        n_normal_samples = sample_size - n_fraud_samples\n",
        "        fraud_indices = np.where(self.y == 1)[0]\n",
        "        normal_indices = np.where(self.y == 0)[0]\n",
        "        np.random.seed(self.random_state)\n",
        "        sampled_fraud_idx = np.random.choice(fraud_indices,\n",
        "                                           min(n_fraud_samples, len(fraud_indices)),\n",
        "                                           replace=False)\n",
        "        sampled_normal_idx = np.random.choice(normal_indices,\n",
        "                                            min(n_normal_samples, len(normal_indices)),\n",
        "                                            replace=False)\n",
        "        sampled_indices = np.concatenate([sampled_fraud_idx, sampled_normal_idx])\n",
        "        np.random.shuffle(sampled_indices)\n",
        "        self.X = self.X[sampled_indices]\n",
        "        self.y = self.y[sampled_indices]\n",
        "        self.class_distribution = Counter(self.y)\n",
        "        print(f\"Sampled dataset:\")\n",
        "        print(f\"Normal transactions: {self.class_distribution[0]:,}\")\n",
        "        print(f\"Fraud transactions: {self.class_distribution[1]:,}\")\n",
        "        print(f\"Fraud percentage: {(self.class_distribution[1]/len(self.y)*100):.3f}%\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8527a4bb"
      },
      "source": [
        "### 2. Cross-Validation Implementation\n",
        "\n",
        "The `analyze_fold_distributions` method demonstrates how `KFold` and `StratifiedKFold` are used and analyzes the class distribution within each fold for both strategies. This is crucial for understanding why stratified cross-validation is necessary for imbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65805419"
      },
      "source": [
        "# From the original code, within the CreditCardFraudAnalyzer class:\n",
        "# (Only showing the relevant method)\n",
        "\n",
        "def analyze_fold_distributions(self):\n",
        "    \"\"\"\n",
        "    Analyze class distributions across different fold strategies\n",
        "    \"\"\"\n",
        "    kfold = KFold(n_splits=self.k_folds, shuffle=True, random_state=self.random_state)\n",
        "    stratified_kfold = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=self.random_state)\n",
        "    kfold_distributions = []\n",
        "    stratified_distributions = []\n",
        "\n",
        "    print(\"\\nAnalyzing fold distributions...\")\n",
        "\n",
        "    # Analyze K-Fold distributions\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(self.X, self.y)):\n",
        "        val_distribution = Counter(self.y[val_idx])\n",
        "        fraud_ratio = val_distribution[1] / len(val_idx) if len(val_idx) > 0 else 0\n",
        "        kfold_distributions.append({\n",
        "            'fold': fold + 1,\n",
        "            'fraud_count': val_distribution[1],\n",
        "            'normal_count': val_distribution[0],\n",
        "            'fraud_ratio': fraud_ratio,\n",
        "            'total_samples': len(val_idx)\n",
        "        })\n",
        "\n",
        "    # Analyze Stratified K-Fold distributions\n",
        "    for fold, (train_idx, val_idx) in enumerate(stratified_kfold.split(self.X, self.y)):\n",
        "        val_distribution = Counter(self.y[val_idx])\n",
        "        fraud_ratio = val_distribution[1] / len(val_idx) if len(val_idx) > 0 else 0\n",
        "        stratified_distributions.append({\n",
        "            'fold': fold + 1,\n",
        "            'fraud_count': val_distribution[1],\n",
        "            'normal_count': val_distribution[0],\n",
        "            'fraud_ratio': fraud_ratio,\n",
        "            'total_samples': len(val_idx)\n",
        "        })\n",
        "\n",
        "    self.kfold_dist_df = pd.DataFrame(kfold_distributions)\n",
        "    self.stratified_dist_df = pd.DataFrame(stratified_distributions)\n",
        "\n",
        "    print(\"\\nFold Distribution Analysis:\")\n",
        "    print(\"K-Fold Cross-Validation:\")\n",
        "    print(f\"  Fraud ratio - Mean: {self.kfold_dist_df['fraud_ratio'].mean():.4f}, \"\n",
        "          f\"Std: {self.kfold_dist_df['fraud_ratio'].std():.4f}\")\n",
        "    print(f\"  Min fraud samples per fold: {self.kfold_dist_df['fraud_count'].min()}\")\n",
        "    print(f\"  Max fraud samples per fold: {self.kfold_dist_df['fraud_count'].max()}\")\n",
        "\n",
        "    print(\"\\nStratified K-Fold Cross-Validation:\")\n",
        "    print(f\"  Fraud ratio - Mean: {self.stratified_dist_df['fraud_ratio'].mean():.4f}, \"\n",
        "          f\"Std: {self.stratified_dist_df['fraud_ratio'].std():.4f}\")\n",
        "    print(f\"  Min fraud samples per fold: {self.stratified_dist_df['fraud_count'].min()}\")\n",
        "    print(f\"  Max fraud samples per fold: {self.stratified_dist_df['fraud_count'].max()}\")\n",
        "\n",
        "    return self.kfold_dist_df, self.stratified_dist_df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19caef2c"
      },
      "source": [
        "### 3. Model Training and Evaluation\n",
        "\n",
        "The `train_and_evaluate_models` method trains multiple classification models using both K-Fold and Stratified K-Fold. It calculates the required performance metrics (Accuracy, Precision, Recall, F1-score, and ROC-AUC) for each fold and stores the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e7e6594"
      },
      "source": [
        "# From the original code, within the CreditCardFraudAnalyzer class:\n",
        "# (Only showing the relevant method)\n",
        "\n",
        "def train_and_evaluate_models(self):\n",
        "    \"\"\"\n",
        "    Train multiple models using both cross-validation strategies\n",
        "    \"\"\"\n",
        "    models = {\n",
        "        'Random Forest': RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            class_weight='balanced',\n",
        "            random_state=self.random_state,\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(\n",
        "            n_estimators=100,\n",
        "            random_state=self.random_state\n",
        "        ),\n",
        "        'Logistic Regression': LogisticRegression(\n",
        "            class_weight='balanced',\n",
        "            random_state=self.random_state,\n",
        "            max_iter=1000\n",
        "        ),\n",
        "        'SVM': SVC(\n",
        "            class_weight='balanced',\n",
        "            probability=True,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "    }\n",
        "\n",
        "    kfold = KFold(n_splits=self.k_folds, shuffle=True, random_state=self.random_state)\n",
        "    stratified_kfold = StratifiedKFold(n_splits=self.k_folds, shuffle=True, random_state=self.random_state)\n",
        "\n",
        "    self.results = {\n",
        "        'K-Fold': {model_name: {'accuracy': [], 'precision': [], 'recall': [],\n",
        "                               'f1': [], 'roc_auc': []} for model_name in models.keys()},\n",
        "        'Stratified K-Fold': {model_name: {'accuracy': [], 'precision': [], 'recall': [],\n",
        "                                          'f1': [], 'roc_auc': []} for model_name in models.keys()}\n",
        "    }\n",
        "\n",
        "    print(\"\\nStandardizing features...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(self.X)\n",
        "\n",
        "    # Evaluate with K-Fold\n",
        "    print(\"Evaluating with K-Fold Cross-Validation...\")\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"  Training {model_name}...\")\n",
        "        for fold, (train_idx, val_idx) in enumerate(kfold.split(X_scaled, self.y)):\n",
        "            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "            y_train, y_val = self.y[train_idx], self.y[val_idx]\n",
        "\n",
        "            if len(np.unique(y_val)) < 2:\n",
        "                print(f\"    Warning: Fold {fold+1} has only one class. Skipping...\")\n",
        "                for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
        "                    self.results['K-Fold'][model_name][metric].append(np.nan)\n",
        "                continue\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_val)\n",
        "            y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "            self.results['K-Fold'][model_name]['accuracy'].append(accuracy_score(y_val, y_pred))\n",
        "            self.results['K-Fold'][model_name]['precision'].append(precision_score(y_val, y_pred, zero_division=0))\n",
        "            self.results['K-Fold'][model_name]['recall'].append(recall_score(y_val, y_pred, zero_division=0))\n",
        "            self.results['K-Fold'][model_name]['f1'].append(f1_score(y_val, y_pred, zero_division=0))\n",
        "            self.results['K-Fold'][model_name]['roc_auc'].append(roc_auc_score(y_val, y_pred_proba))\n",
        "\n",
        "    # Evaluate with Stratified K-Fold\n",
        "    print(\"Evaluating with Stratified K-Fold Cross-Validation...\")\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"  Training {model_name}...\")\n",
        "        for fold, (train_idx, val_idx) in enumerate(stratified_kfold.split(X_scaled, self.y)):\n",
        "            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "            y_train, y_val = self.y[train_idx], self.y[val_idx]\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_val)\n",
        "            y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "            self.results['Stratified K-Fold'][model_name]['accuracy'].append(accuracy_score(y_val, y_pred))\n",
        "            self.results['Stratified K-Fold'][model_name]['precision'].append(precision_score(y_val, y_pred, zero_division=0))\n",
        "            self.results['Stratified K-Fold'][model_name]['recall'].append(recall_score(y_val, y_pred, zero_division=0))\n",
        "            self.results['Stratified K-Fold'][model_name]['f1'].append(f1_score(y_val, y_pred, zero_division=0))\n",
        "            self.results['Stratified K-Fold'][model_name]['roc_auc'].append(roc_auc_score(y_val, y_pred_proba))\n",
        "\n",
        "    print(\"Model training and evaluation completed!\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2773940d"
      },
      "source": [
        "### 4. Performance Comparison and Stability Analysis\n",
        "\n",
        "The `calculate_stability_metrics` method computes the mean, standard deviation, and coefficient of variation for each metric across the folds, providing insights into model stability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abe6c207"
      },
      "source": [
        "# From the original code, within the CreditCardFraudAnalyzer class:\n",
        "# (Only showing the relevant method)\n",
        "\n",
        "def calculate_stability_metrics(self):\n",
        "    \"\"\"\n",
        "    Calculate stability metrics for each model and method\n",
        "    \"\"\"\n",
        "    stability_results = {}\n",
        "\n",
        "    for method in ['K-Fold', 'Stratified K-Fold']:\n",
        "        stability_results[method] = {}\n",
        "        for model_name in self.results[method].keys():\n",
        "            model_stability = {}\n",
        "            for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
        "                scores = [score for score in self.results[method][model_name][metric] if not np.isnan(score)]\n",
        "                if scores:\n",
        "                    mean_score = np.mean(scores)\n",
        "                    std_score = np.std(scores)\n",
        "                    cv_score = std_score / mean_score if mean_score != 0 else 0\n",
        "                else:\n",
        "                    mean_score = std_score = cv_score = 0\n",
        "\n",
        "                model_stability[metric] = {\n",
        "                    'mean': mean_score,\n",
        "                    'std': std_score,\n",
        "                    'cv': cv_score,\n",
        "                    'valid_folds': len(scores)\n",
        "                }\n",
        "            stability_results[method][model_name] = model_stability\n",
        "\n",
        "    return stability_results"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a202912f"
      },
      "source": [
        "### 5. Visualizations\n",
        "\n",
        "The `create_comprehensive_visualizations` method generates plots to visually compare the fold-wise class distribution and the performance metrics across both cross-validation strategies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b2ebc87"
      },
      "source": [
        "# From the original code, within the CreditCardFraudAnalyzer class:\n",
        "# (Only showing the relevant method)\n",
        "\n",
        "def create_comprehensive_visualizations(self):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualizations for fraud detection analysis\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(20, 28))\n",
        "\n",
        "    # 1. Dataset Overview\n",
        "    plt.subplot(5, 3, 1)\n",
        "    class_names = ['Normal', 'Fraud']\n",
        "    class_counts = [self.class_distribution[0], self.class_distribution[1]]\n",
        "    colors = ['lightblue', 'lightcoral']\n",
        "    plt.pie(class_counts, labels=class_names, autopct='%1.3f%%', colors=colors, startangle=90)\n",
        "    plt.title('Credit Card Transaction Distribution')\n",
        "\n",
        "    # 2. Fraud Distribution Across Folds\n",
        "    plt.subplot(5, 3, 2)\n",
        "    x = range(1, self.k_folds + 1)\n",
        "    plt.bar([i - 0.2 for i in x], self.kfold_dist_df['fraud_ratio'],\n",
        "            width=0.4, label='K-Fold', alpha=0.7, color='coral')\n",
        "    plt.bar([i + 0.2 for i in x], self.stratified_dist_df['fraud_ratio'],\n",
        "            width=0.4, label='Stratified K-Fold', alpha=0.7, color='lightblue')\n",
        "    plt.xlabel('Fold Number')\n",
        "    plt.ylabel('Fraud Ratio')\n",
        "    plt.title('Fraud Distribution Across Folds')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Standard Deviation of Fraud Distribution\n",
        "    plt.subplot(5, 3, 3)\n",
        "    methods = ['K-Fold', 'Stratified K-Fold']\n",
        "    std_values = [self.kfold_dist_df['fraud_ratio'].std(),\n",
        "                 self.stratified_dist_df['fraud_ratio'].std()]\n",
        "    bars = plt.bar(methods, std_values, color=['coral', 'lightblue'])\n",
        "    plt.ylabel('Standard Deviation')\n",
        "    plt.title('Fraud Distribution Stability')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    for bar, value in zip(bars, std_values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0001,\n",
        "                f'{value:.5f}', ha='center', va='bottom')\n",
        "\n",
        "    # 4. Fraud Count Variability\n",
        "    plt.subplot(5, 3, 4)\n",
        "    plt.boxplot([self.kfold_dist_df['fraud_count'], self.stratified_dist_df['fraud_count']],\n",
        "               labels=['K-Fold', 'Stratified K-Fold'])\n",
        "    plt.ylabel('Fraud Cases per Fold')\n",
        "    plt.title('Fraud Count Variability Across Folds')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 5-14. Performance Metrics Boxplots\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "    model_names = list(self.results['K-Fold'].keys())\n",
        "\n",
        "    plot_positions = [(5, 3, 5), (5, 3, 6), (5, 3, 7), (5, 3, 8), (5, 3, 9),\n",
        "                     (5, 3, 10), (5, 3, 11), (5, 3, 12), (5, 3, 13), (5, 3, 14)]\n",
        "\n",
        "    for idx, metric in enumerate(metrics):\n",
        "        plt.subplot(*plot_positions[idx])\n",
        "        data_to_plot = []\n",
        "        labels = []\n",
        "\n",
        "        for model_name in model_names:\n",
        "            for method in ['K-Fold', 'Stratified K-Fold']:\n",
        "                scores = [score for score in self.results[method][model_name][metric] if not np.isnan(score)]\n",
        "                data_to_plot.append(scores)\n",
        "                labels.append(f'{model_name}\\n({method})')\n",
        "\n",
        "        box_plot = plt.boxplot(data_to_plot, patch_artist=True, labels=labels)\n",
        "\n",
        "        colors = ['lightcoral', 'lightblue'] * len(model_names)\n",
        "        for patch, color in zip(box_plot['boxes'], colors):\n",
        "            patch.set_facecolor(color)\n",
        "            patch.set_alpha(0.7)\n",
        "\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylabel(metric.replace('_', ' ').title())\n",
        "        plt.title(f'{metric.replace(\"_\", \" \").title()} - Fraud Detection')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 15. Performance Summary Heatmap\n",
        "    plt.subplot(5, 3, 15)\n",
        "\n",
        "    summary_data = []\n",
        "    for method in ['K-Fold', 'Stratified K-Fold']:\n",
        "        for model_name in model_names:\n",
        "            for metric in metrics:\n",
        "                scores = [score for score in self.results[method][model_name][metric] if not np.isnan(scores)]\n",
        "                mean_score = np.mean(scores) if scores else 0\n",
        "                summary_data.append([method, model_name, metric, mean_score])\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data, columns=['Method', 'Model', 'Metric', 'Score'])\n",
        "    pivot_df = summary_df.pivot_table(index=['Method', 'Model'], columns='Metric', values='Score')\n",
        "\n",
        "    sns.heatmap(pivot_df, annot=True, fmt='.3f', cmap='RdYlBu_r',\n",
        "               cbar_kws={'label': 'Score'})\n",
        "    plt.title('Credit Card Fraud Detection - Performance Summary')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d689cd2"
      },
      "source": [
        "### 6. Comprehensive Report Generation\n",
        "\n",
        "The `generate_comprehensive_report` method consolidates the analysis, including dataset information, fold distribution analysis, performance comparison, stability analysis, and critical explanations of the findings. This directly addresses the report deliverable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ca4464a"
      },
      "source": [
        "# From the original code, within the CreditCardFraudAnalyzer class:\n",
        "# (Only showing the relevant method)\n",
        "\n",
        "def generate_comprehensive_report(self):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive analysis report for credit card fraud detection\n",
        "    \"\"\"\n",
        "    stability_results = self.calculate_stability_metrics()\n",
        "\n",
        "    print(\"=\"*90)\n",
        "    print(\"COMPREHENSIVE ANALYSIS REPORT\")\n",
        "    print(\"K-Fold vs Stratified K-Fold Cross-Validation for Credit Card Fraud Detection\")\n",
        "    print(\"=\"*90)\n",
        "\n",
        "    # Dataset Information\n",
        "    print(\"\\n1. DATASET INFORMATION\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"Dataset: Credit Card Fraud Detection\")\n",
        "    print(f\"Total samples: {self.dataset_info['total_samples']:,}\")\n",
        "    print(f\"Features: {self.dataset_info['n_features']}\")\n",
        "    print(f\"Normal transactions: {self.dataset_info['normal_transactions']:,} \"\n",
        "          f\"({(self.dataset_info['normal_transactions']/self.dataset_info['total_samples']*100):.3f}%)\")\n",
        "    print(f\"Fraud transactions: {self.dataset_info['fraud_transactions']:,} \"\n",
        "          f\"({self.dataset_info['fraud_percentage']:.3f}%)\")\n",
        "    print(f\"Imbalance ratio: 1:{self.dataset_info['normal_transactions']/self.dataset_info['fraud_transactions']:.0f}\")\n",
        "\n",
        "    # Fold Distribution Analysis\n",
        "    print(\"\\n2. FOLD DISTRIBUTION ANALYSIS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"K-Fold Cross-Validation:\")\n",
        "    print(f\"  Fraud ratio - Mean: {self.kfold_dist_df['fraud_ratio'].mean():.5f}, \"\n",
        "          f\"Std: {self.kfold_dist_df['fraud_ratio'].std():.5f}\")\n",
        "    print(f\"  Fraud count range: {self.kfold_dist_df['fraud_count'].min()} - {self.kfold_dist_df['fraud_count'].max()}\")\n",
        "\n",
        "    print(\"\\nStratified K-Fold Cross-Validation:\")\n",
        "    print(f\"  Fraud ratio - Mean: {self.stratified_dist_df['fraud_ratio'].mean():.5f}, \"\n",
        "          f\"Std: {self.stratified_dist_df['fraud_ratio'].std():.5f}\")\n",
        "    print(f\"  Fraud count range: {self.stratified_dist_df['fraud_count'].min()} - {self.stratified_dist_df['fraud_count'].max()}\")\n",
        "\n",
        "    # Performance Comparison\n",
        "    print(\"\\n3. PERFORMANCE COMPARISON\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for model_name in self.results['K-Fold'].keys():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(\"  Metric           K-Fold (Mean±Std)      Stratified K-Fold (Mean±Std)    Valid Folds\")\n",
        "        print(\"  \" + \"-\" * 80)\n",
        "\n",
        "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
        "            kfold_stats = stability_results['K-Fold'][model_name][metric]\n",
        "            stratified_stats = stability_results['Stratified K-Fold'][model_name][metric]\n",
        "\n",
        "            print(f\"  {metric:<12} {kfold_stats['mean']:.3f}±{kfold_stats['std']:.3f} ({kfold_stats['valid_folds']})    \"\n",
        "                  f\"{stratified_stats['mean']:.3f}±{stratified_stats['std']:.3f} ({stratified_stats['valid_folds']})\")\n",
        "\n",
        "    # Stability Analysis\n",
        "    print(\"\\n4. STABILITY ANALYSIS (Coefficient of Variation)\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Lower CV values indicate more stable performance across folds\")\n",
        "\n",
        "    for model_name in stability_results['K-Fold'].keys():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(\"  Metric       K-Fold CV    Stratified CV    Improvement\")\n",
        "        print(\"  \" + \"-\" * 55)\n",
        "\n",
        "        for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
        "            kfold_cv = stability_results['K-Fold'][model_name][metric]['cv']\n",
        "            stratified_cv = stability_results['Stratified K-Fold'][model_name][metric]['cv']\n",
        "            improvement = ((kfold_cv - stratified_cv) / kfold_cv * 100) if kfold_cv != 0 else 0\n",
        "\n",
        "            print(f\"  {metric:<12} {kfold_cv:.4f}      {stratified_cv:.4f}      {improvement:+.1f}%\")\n",
        "\n",
        "    # Critical Analysis for Fraud Detection\n",
        "    print(\"\\n5. CRITICAL ANALYSIS FOR FRAUD DETECTION\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    print(\"\\nWhy K-Fold is problematic for fraud detection:\")\n",
        "    print(\"• With only 0.17% fraud cases, some folds may have very few or zero fraud samples\")\n",
        "    print(\"• This makes precision, recall, and F1-score calculations unreliable or undefined\")\n",
        "    print(\"• Model performance estimates become highly variable and misleading\")\n",
        "    print(\"• Risk of completely missing fraud patterns in validation\")\n",
        "\n",
        "    print(\"\\nHow Stratified K-Fold addresses these issues:\")\n",
        "    print(\"• Ensures each fold contains representative fraud samples\")\n",
        "    print(\"• Maintains consistent fraud ratio across all folds\")\n",
        "    print(\"• Enables reliable calculation of all performance metrics\")\n",
        "    print(\"• Provides more realistic estimates of model performance\")\n",
        "\n",
        "    print(\"\\nKey findings for fraud detection:\")\n",
        "    fraud_ratio_improvement = (\n",
        "        (self.kfold_dist_df['fraud_ratio'].std() - self.stratified_dist_df['fraud_ratio'].std()) /\n",
        "        self.kfold_dist_df['fraud_ratio'].std() * 100\n",
        "    )\n",
        "    print(f\"• Stratified K-Fold reduces fraud ratio variability by {fraud_ratio_improvement:.1f}%\")\n",
        "    print(\"• F1-score and Recall are most improved with stratified approach\")\n",
        "    print(\"• All models show better stability with Stratified K-Fold\")\n",
        "\n",
        "    print(\"\\n6. RECOMMENDATIONS FOR FRAUD DETECTION\")\n",
        "    print(\"-\" * 50)\n",
        "    print(\"• ALWAYS use Stratified K-Fold for extremely imbalanced datasets\")\n",
        "    print(\"• Focus on Precision, Recall, F1-score, and ROC-AUC rather than accuracy\")\n",
        "    print(\"• Consider cost-sensitive learning approaches\")\n",
        "    print(\"• Use class balancing techniques (class_weight='balanced')\")\n",
        "    print(\"• Monitor false positive and false negative rates carefully\")\n",
        "    print(\"• Consider ensemble methods for better fraud detection\")\n",
        "\n",
        "    return stability_results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3405ae05"
      },
      "source": [
        "To run the analysis, you can use the `main()` function provided in your original code. Make sure to update the `dataset_path` variable with the correct path to your `creditcard.csv` file if you have downloaded it. If not, the code will use the synthetic dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b28e7074",
        "outputId": "bc595c11-a681-4da1-e317-af1f60dfc7c1"
      },
      "source": [
        "# From the original code:\n",
        "# (Only showing the main function)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the complete analysis\n",
        "    \"\"\"\n",
        "    analyzer = CreditCardFraudAnalyzer(k_folds=5, random_state=42)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"CREDIT CARD FRAUD DETECTION ANALYSIS\")\n",
        "    print(\"K-Fold vs Stratified K-Fold Cross-Validation\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # IMPORTANT: Replace this path with your actual file path\n",
        "    dataset_path = \"creditcard.csv\"  # Change this to your file path\n",
        "    # Examples:\n",
        "    # dataset_path = \"/path/to/your/creditcard.csv\"\n",
        "    # dataset_path = \"C:/Users/YourName/Downloads/creditcard.csv\"\n",
        "    # dataset_path = \"./data/creditcard.csv\"\n",
        "\n",
        "    X, y = analyzer.load_credit_card_dataset(dataset_path)\n",
        "\n",
        "    # Step 2: Sample dataset if it's too large (optional - for faster computation)\n",
        "    # Comment out this line if you want to use the full dataset\n",
        "    analyzer.sample_dataset_for_analysis(sample_size=20000)\n",
        "\n",
        "    # Step 3: Analyze fold distributions\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 1: ANALYZING FOLD DISTRIBUTIONS\")\n",
        "    print(\"=\"*70)\n",
        "    kfold_dist, stratified_dist = analyzer.analyze_fold_distributions()\n",
        "\n",
        "    # Step 4: Train and evaluate models\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 2: TRAINING AND EVALUATING MODELS\")\n",
        "    print(\"=\"*70)\n",
        "    analyzer.train_and_evaluate_models()\n",
        "\n",
        "    # Step 5: Create visualizations\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 3: CREATING COMPREHENSIVE VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    analyzer.create_comprehensive_visualizations()\n",
        "\n",
        "    # Step 6: Generate comprehensive report\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STEP 4: GENERATING COMPREHENSIVE ANALYSIS REPORT\")\n",
        "    print(\"=\"*70)\n",
        "    stability_results = analyzer.generate_comprehensive_report()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ANALYSIS COMPLETE!\")\n",
        "    print(\"All visualizations and analysis have been generated.\")\n",
        "    print(\"Check the plots and detailed report above.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Run the analysis\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CREDIT CARD FRAUD DETECTION ANALYSIS\n",
            "K-Fold vs Stratified K-Fold Cross-Validation\n",
            "======================================================================\n",
            "Loading Credit Card Fraud Detection dataset...\n",
            "Dataset loaded successfully!\n",
            "Total samples: 31,780\n",
            "Features: 30\n",
            "Normal transactions: 31,677 (99.68%)\n",
            "Fraud transactions: 102 (0.321%)\n",
            "Imbalance ratio: 1:311\n",
            "\n",
            "Sampling 20,000 samples for analysis (maintaining class distribution)...\n",
            "Sampled dataset:\n",
            "Normal transactions: 19,936\n",
            "Fraud transactions: 64\n",
            "Fraud percentage: 0.320%\n",
            "\n",
            "======================================================================\n",
            "STEP 1: ANALYZING FOLD DISTRIBUTIONS\n",
            "======================================================================\n",
            "\n",
            "Analyzing fold distributions...\n",
            "\n",
            "Fold Distribution Analysis:\n",
            "K-Fold Cross-Validation:\n",
            "  Fraud ratio - Mean: 0.0032, Std: 0.0006\n",
            "  Min fraud samples per fold: 10\n",
            "  Max fraud samples per fold: 15\n",
            "\n",
            "Stratified K-Fold Cross-Validation:\n",
            "  Fraud ratio - Mean: 0.0032, Std: 0.0001\n",
            "  Min fraud samples per fold: 12\n",
            "  Max fraud samples per fold: 13\n",
            "\n",
            "======================================================================\n",
            "STEP 2: TRAINING AND EVALUATING MODELS\n",
            "======================================================================\n",
            "\n",
            "Standardizing features...\n",
            "Evaluating with K-Fold Cross-Validation...\n",
            "  Training Random Forest...\n",
            "  Training Gradient Boosting...\n",
            "  Training Logistic Regression...\n",
            "  Training SVM...\n",
            "Evaluating with Stratified K-Fold Cross-Validation...\n",
            "  Training Random Forest...\n",
            "  Training Gradient Boosting...\n",
            "  Training Logistic Regression...\n",
            "  Training SVM...\n",
            "Model training and evaluation completed!\n",
            "\n",
            "======================================================================\n",
            "STEP 3: CREATING COMPREHENSIVE VISUALIZATIONS\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jh4w3MaeVj57"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}